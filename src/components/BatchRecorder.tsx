import React, { useState, useCallback, useRef, useEffect } from 'react';
import { useWhisperSTT } from '../useWhisperSTT';
import { Transcript } from '../types';

interface TimestampedSegment {
  text: string;
  start: number;
  end: number;
}

interface BatchRecorderProps {
  currentLanguage: 'korean' | 'english';
  isModelReady: boolean;
  isModelLoading: boolean;
  sttError: string | null;
  onRecordingStateChange?: (state: { isRecording: boolean; isPaused: boolean }) => void;
}

export const BatchRecorder: React.FC<BatchRecorderProps> = ({ 
  currentLanguage, 
  isModelReady, 
  isModelLoading, 
  sttError,
  onRecordingStateChange
}) => {
  const [transcripts, setTranscripts] = useState<Transcript[]>([]);
  const [timestampedSegments, setTimestampedSegments] = useState<TimestampedSegment[]>([]);
  const [recordingStartTime, setRecordingStartTime] = useState<number | null>(null);
  const [recordingDuration, setRecordingDuration] = useState<number>(0);
  const [isPaused, setIsPaused] = useState<boolean>(false);
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [isProcessingBatch, setIsProcessingBatch] = useState<boolean>(false);
  
  // ì˜¤ë””ì˜¤ ê´€ë ¨ refs
  const streamRef = useRef<MediaStream | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const durationIntervalRef = useRef<number | null>(null);
  
  const {
    transcribeAudio
  } = useWhisperSTT();

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„ ì‹œì‘
  const startAudioLevelAnalysis = useCallback((stream: MediaStream) => {
    try {
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      
      analyser.fftSize = 128;
      analyser.smoothingTimeConstant = 0.9;
      source.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateAudioLevel = () => {
        if (!analyserRef.current) return;
        
        analyserRef.current.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((acc, value) => acc + value, 0) / dataArray.length;
        const normalizedLevel = Math.min(100, (average / 128) * 100);
        const roundedLevel = Math.round(normalizedLevel);
        
        setAudioLevel(prev => prev !== roundedLevel ? roundedLevel : prev);
        
        setTimeout(() => {
          animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
        }, 33);
      };
      
      updateAudioLevel();
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }, []);

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„ ì¤‘ì§€
  const stopAudioLevelAnalysis = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    
    analyserRef.current = null;
    setAudioLevel(0);
  }, []);

  // ë…¹ìŒ ì‹œê°„ ì—…ë°ì´íŠ¸
  const startDurationTimer = useCallback(() => {
    durationIntervalRef.current = window.setInterval(() => {
      if (recordingStartTime && !isPaused) {
        setRecordingDuration(Math.floor((Date.now() - recordingStartTime) / 1000));
      }
    }, 1000);
  }, [recordingStartTime, isPaused]);

  const stopDurationTimer = useCallback(() => {
    if (durationIntervalRef.current) {
      clearInterval(durationIntervalRef.current);
      durationIntervalRef.current = null;
    }
  }, []);

  const handleStartRecording = useCallback(async () => {
    if (!isModelReady) {
      alert(`ëª¨ë¸ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\nìƒíƒœ: ${isModelLoading ? 'ë¡œë”© ì¤‘...' : 'ì¤€ë¹„ ì¤‘'}\n${sttError ? `ì˜¤ë¥˜: ${sttError}` : ''}`);
      return;
    }

    try {
      console.log('ğŸ¬ ë°°ì¹˜ ë…¹ìŒ ì‹œì‘');
      
      // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      streamRef.current = stream;
      
      // MediaRecorder ì„¤ì •
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      // ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„ ì‹œì‘
      startAudioLevelAnalysis(stream);
      
      // ë…¹ìŒ ì‹œì‘
      mediaRecorder.start();
      setIsRecording(true);
      onRecordingStateChange?.({ isRecording: true, isPaused: false });
      setRecordingStartTime(Date.now());
      setRecordingDuration(0);
      setTranscripts([]);
      setTimestampedSegments([]);
      
      // ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹œì‘
      startDurationTimer();
      
    } catch (err) {
      console.error('ë°°ì¹˜ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', err);
      const errorMessage = err instanceof Error ? err.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
      alert('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ' + errorMessage);
    }
  }, [isModelReady, isModelLoading, sttError, startAudioLevelAnalysis, startDurationTimer, onRecordingStateChange]);

  const handlePauseRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.pause();
    }
    
    stopAudioLevelAnalysis();
    stopDurationTimer();
    setIsPaused(true);
    onRecordingStateChange?.({ isRecording: true, isPaused: true });
    console.log('â¸ï¸ ë°°ì¹˜ ë…¹ìŒ ì¼ì‹œì •ì§€');
  }, [stopAudioLevelAnalysis, stopDurationTimer, onRecordingStateChange]);

  const handleResumeRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'paused') {
      mediaRecorderRef.current.resume();
    }
    
    if (streamRef.current) {
      startAudioLevelAnalysis(streamRef.current);
    }
    
    startDurationTimer();
    setIsPaused(false);
    onRecordingStateChange?.({ isRecording: true, isPaused: false });
    console.log('â–¶ï¸ ë°°ì¹˜ ë…¹ìŒ ì¬ê°œ');
  }, [startAudioLevelAnalysis, startDurationTimer, onRecordingStateChange]);

  const handleStopRecording = useCallback(async () => {
    console.log('ğŸ›‘ ë°°ì¹˜ ë…¹ìŒ ì¢…ë£Œ ë° STT ì²˜ë¦¬ ì‹œì‘');
    
    // ë…¹ìŒ ì¢…ë£Œ
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }
    
    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    stopAudioLevelAnalysis();
    stopDurationTimer();
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    setIsRecording(false);
    setIsPaused(false);
    onRecordingStateChange?.({ isRecording: false, isPaused: false });
    setIsProcessingBatch(true);
    
    // ë…¹ìŒ ë°ì´í„°ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ì ê¹ ëŒ€ê¸°
    await new Promise(resolve => setTimeout(resolve, 100));
    
    try {
      // ì „ì²´ ì˜¤ë””ì˜¤ blob ìƒì„±
      const fullBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
      console.log('ğŸ“¦ ì „ì²´ ì˜¤ë””ì˜¤ blob ìƒì„± ì™„ë£Œ, í¬ê¸°:', fullBlob.size);
      
      if (fullBlob.size === 0) {
        throw new Error('ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤');
      }
      
      // STT ì²˜ë¦¬ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
      console.log(`ğŸŒ ë°°ì¹˜ STT ì²˜ë¦¬ ì‹œì‘ - ì–¸ì–´: ${currentLanguage}`);
      const result = await transcribeAudio(fullBlob, recordingStartTime || Date.now(), currentLanguage, true);
      
      console.log('âœ… ë°°ì¹˜ STT ì²˜ë¦¬ ì™„ë£Œ:', result);
      
      // íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ìˆëŠ” ê²½ìš° ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ë¶„ë¦¬
      if (result.chunks && result.chunks.length > 0) {
        const startTime = recordingStartTime || Date.now();
        const newTranscripts: Transcript[] = result.chunks.map((chunk, index) => ({
          id: startTime + index,
          text: chunk.text,
          timestamp: startTime + (chunk.timestamp[0] * 1000), // ì´ˆë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
          segmentNumber: index + 1,
          processedAt: Date.now(),
          recordingStartTime: recordingStartTime
        }));
        
        const segments: TimestampedSegment[] = result.chunks.map(chunk => ({
          text: chunk.text,
          start: chunk.timestamp[0],
          end: chunk.timestamp[1]
        }));
        
        setTranscripts(newTranscripts);
        setTimestampedSegments(segments);
        console.log('âœ… íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±:', segments.length, 'ê°œ');
      } else {
        // íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
        const finalTranscript: Transcript = {
          id: recordingStartTime || Date.now(),
          text: result.text,
          timestamp: recordingStartTime || Date.now(),
          segmentNumber: 1,
          processedAt: Date.now(),
          recordingStartTime: recordingStartTime
        };
        
        setTranscripts([finalTranscript]);
        setTimestampedSegments([]);
      }
      
    } catch (error) {
      console.error('ë°°ì¹˜ STT ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
      
      const errorTranscript: Transcript = {
        id: recordingStartTime || Date.now(),
        text: `[ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: ${errorMessage}]`,
        timestamp: recordingStartTime || Date.now(),
        segmentNumber: 1,
        processedAt: Date.now(),
        recordingStartTime: recordingStartTime,
        isError: true
      };
      
      setTranscripts([errorTranscript]);
      setTimestampedSegments([]);
    } finally {
      setIsProcessingBatch(false);
      chunksRef.current = [];
    }
  }, [transcribeAudio, currentLanguage, recordingStartTime, stopAudioLevelAnalysis, stopDurationTimer, onRecordingStateChange]);

  const formatDuration = useCallback((seconds: number): string => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  }, []);

  const formatTime = useCallback((seconds: number): string => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = Math.floor(seconds % 60);
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  }, []);

  const downloadAsText = useCallback(() => {
    if (transcripts.length === 0) {
      alert('ë‹¤ìš´ë¡œë“œí•  íšŒì˜ë¡ì´ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    const meetingDate = new Date().toLocaleDateString('ko-KR');
    const meetingTime = recordingStartTime ? new Date(recordingStartTime).toLocaleTimeString('ko-KR') : '';
    
    let content = `íšŒì˜ë¡ (í•œë²ˆì— ì²˜ë¦¬ ëª¨ë“œ)\n`;
    content += `ë‚ ì§œ: ${meetingDate}\n`;
    content += `ì‹œì‘ ì‹œê°„: ${meetingTime}\n`;
    content += `ë…¹ìŒ ì‹œê°„: ${formatDuration(recordingDuration)}\n`;
    content += `ì–¸ì–´: ${currentLanguage === 'korean' ? 'í•œêµ­ì–´' : 'ì˜ì–´'}\n`;
    content += `ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: ${transcripts.length}ê°œ\n\n`;
    content += `${'='.repeat(50)}\n\n`;

    if (timestampedSegments.length > 0) {
      // íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ì„¸ê·¸ë¨¼íŠ¸ í‘œì‹œ
      timestampedSegments.forEach((segment, index) => {
        const startTime = formatTime(segment.start);
        const endTime = formatTime(segment.end);
        content += `[${startTime} - ${endTime}]\n`;
        content += `${segment.text || '(í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤)'}\n\n`;
      });
    } else {
      // ì „ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ
      transcripts.forEach(transcript => {
        content += `${transcript.text || '(í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤)'}\n\n`;
      });
    }

    const blob = new Blob([content], { type: 'text/plain;charset=utf-8' });
    const url = URL.createObjectURL(blob);
    const link = document.createElement('a');
    link.href = url;
    link.download = `ë°°ì¹˜íšŒì˜ë¡_${meetingDate.replace(/\./g, '')}_${new Date().getTime()}.txt`;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    URL.revokeObjectURL(url);
  }, [transcripts, timestampedSegments, recordingStartTime, formatDuration, recordingDuration, currentLanguage, formatTime]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      stopAudioLevelAnalysis();
      stopDurationTimer();
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, [stopAudioLevelAnalysis, stopDurationTimer]);

  return (
    <div className="space-y-6">
      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ ì„¹ì…˜ - ê°•ì¡° (ë‹¤í¬) */}
      <div className="bg-gray-900 text-gray-100 rounded-xl shadow-sm border border-gray-800 p-8">
        <div className="flex flex-col items-center gap-8">
          {/* ë…¹ìŒ ë²„íŠ¼ë“¤ - ë” í° í¬ê¸°ë¡œ ê°•ì¡° */}
          <div className="flex items-center justify-center gap-6">
            {!isRecording ? (
              <div className="flex flex-col items-center gap-2">
                <button
                  aria-label="ë…¹ìŒ ì‹œì‘"
                  className={`w-16 h-16 rounded-full shadow-lg hover:shadow-xl transition-all duration-200 flex items-center justify-center group ${
                    isModelReady 
                      ? 'bg-red-500 hover:bg-red-600' 
                      : 'bg-gray-600 cursor-not-allowed'
                  }`}
                  onClick={handleStartRecording}
                  disabled={!isModelReady}
                >
                  <div className={`w-5 h-5 rounded-full group-hover:scale-110 transition-transform ${
                    isModelReady ? 'bg-white' : 'bg-gray-300'
                  }`}></div>
                </button>
                <span className={`text-sm ${isModelReady ? 'text-white' : 'text-gray-400'}`}>ë…¹ìŒ ì‹œì‘</span>
              </div>
            ) : (
              <div className="flex items-center justify-center gap-8">
                <div className="flex flex-col items-center gap-2">
                  <button
                    aria-label={isPaused ? 'ë…¹ìŒ ì¬ê°œ' : 'ë…¹ìŒ ì¼ì‹œì •ì§€'}
                    className={`w-16 h-16 rounded-full shadow-lg hover:shadow-xl transition-all duration-200 flex items-center justify-center group ${
                      isPaused 
                        ? 'bg-green-500 hover:bg-green-600' 
                        : 'bg-yellow-500 hover:bg-yellow-600'
                    }`}
                    onClick={isPaused ? handleResumeRecording : handlePauseRecording}
                  >
                    {isPaused ? (
                      <div className="w-0 h-0 border-l-[10px] border-l-white border-t-[8px] border-t-transparent border-b-[8px] border-b-transparent ml-1 group-hover:scale-110 transition-transform"></div>
                    ) : (
                      <div className="flex gap-1.5">
                        <div className="w-2 h-6 bg-white rounded-sm"></div>
                        <div className="w-2 h-6 bg-white rounded-sm"></div>
                      </div>
                    )}
                  </button>
                  <span className="text-sm text-white">{isPaused ? 'ë…¹ìŒ ì¬ê°œ' : 'ë…¹ìŒ ì¼ì‹œì •ì§€'}</span>
                </div>
                <div className="flex flex-col items-center gap-2">
                  <button
                    aria-label="ì¢…ë£Œ"
                    className="w-16 h-16 rounded-full bg-red-500 hover:bg-red-600 shadow-lg hover:shadow-xl transition-all duration-200 flex items-center justify-center relative group"
                    onClick={handleStopRecording}
                  >
                    <div className="w-5 h-5 bg-white rounded-sm group-hover:scale-110 transition-transform"></div>
                    {isRecording && !isPaused && (
                      <div className="absolute -top-2 -right-2 w-4 h-4 bg-red-400 rounded-full animate-pulse"></div>
                    )}
                  </button>
                  <span className="text-sm text-white">ì¢…ë£Œ</span>
                </div>
              </div>
            )}
          </div>

          {/* ë…¹ìŒ ì •ë³´ ë° ìŒëŸ‰ ì²´í¬ - ê°•ì¡° */}
          {isRecording && (
            <div className="flex flex-col items-center gap-4">
              <div className="flex items-center gap-4 text-sm text-gray-300">
                <div className="flex items-center gap-2">
                  <span className="text-gray-300">â±ï¸</span>
                  <span>ë…¹ìŒ ì‹œê°„: <span className="font-semibold text-white">{formatDuration(recordingDuration)}</span></span>
                </div>
              </div>
              
              {/* ìŒëŸ‰ ë°” - ë” ì‹œê°ì ìœ¼ë¡œ ê°•ì¡° */}
              <div className="flex items-center gap-3">
                <span className="text-xs text-gray-400">ìŒëŸ‰</span>
                <div className="flex items-end gap-1 h-8">
                  {[...Array(10)].map((_, i) => (
                    <div
                      key={i}
                      className={`w-2 volume-bar rounded-sm ${
                        audioLevel > (i * 10) 
                          ? i < 3 ? 'bg-green-500' : i < 7 ? 'bg-yellow-500' : 'bg-red-500'
                          : 'bg-gray-600'
                      }`}
                      style={{ height: `${Math.max(6, (i + 1) * 2.5)}px` }}
                    ></div>
                  ))}
                </div>
              </div>
            </div>
          )}
        </div>
      </div>

      {/* ìƒíƒœ í‘œì‹œ */}
      {isProcessingBatch && (
        <div className="flex items-center justify-center gap-2 text-yellow-700 py-2">
          <div className="spinner"></div>
          <span>ì „ì²´ ìŒì„±ì„ STT ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...</span>
        </div>
      )}

      {/* ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ - ì‹¬í”Œí•˜ê²Œ */}
      {transcripts.length > 0 && !isRecording && !isProcessingBatch && (
        <div className="bg-white border border-gray-200 rounded-xl p-6">
          <div className="flex items-center justify-between mb-4">
            <h3 className="text-lg font-semibold text-gray-900">íšŒì˜ë¡ ë‹¤ìš´ë¡œë“œ</h3>
            <span className="text-sm text-gray-500">{formatDuration(recordingDuration)} â€¢ {transcripts.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸</span>
          </div>
          <button 
            className="bg-gray-900 hover:bg-gray-800 text-white px-6 py-3 rounded-lg font-medium transition-all duration-200 hover:-translate-y-0.5 shadow-sm"
            onClick={downloadAsText}
          >
            ğŸ“„ TXT ë‹¤ìš´ë¡œë“œ
          </button>
        </div>
      )}

      {/* ì˜¤ë¥˜ í‘œì‹œ */}
      {sttError && (
        <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded-lg">
          <span className="font-medium">ì˜¤ë¥˜:</span> {sttError}
        </div>
      )}

      {/* STT ê²°ê³¼ - ê°„ë‹¨í•˜ê²Œ ìœ ì§€ */}
      <div className="bg-white border border-gray-200 rounded-xl p-6">
        <h3 className="text-lg font-semibold text-gray-900 mb-4">íšŒì˜ ë‚´ìš©</h3>
        
        <div className="max-h-96 overflow-y-auto">
          {transcripts.length === 0 && !isRecording && !isProcessingBatch && (
            <p className="text-gray-500 italic text-center py-8">
              ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë°°ì¹˜ íšŒì˜ë¥¼ ì‹œì‘í•˜ì„¸ìš”.<br />
              ë…¹ìŒ ì¢…ë£Œ í›„ ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.
            </p>
          )}

          {isRecording && (
            <p className="text-gray-500 italic text-center py-8">
              ë°°ì¹˜ ë…¹ìŒ ì¤‘... ì¢…ë£Œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì „ì²´ ë‚´ìš©ì„ STT ì²˜ë¦¬í•©ë‹ˆë‹¤.<br />
              í˜„ì¬ ë…¹ìŒ ì‹œê°„: <span className="font-medium text-gray-900">{formatDuration(recordingDuration)}</span>
            </p>
          )}

          {isProcessingBatch && (
            <div className="flex items-center justify-center gap-2 text-yellow-700 py-8">
              <div className="spinner"></div>
              <span>ì „ì²´ ìŒì„±ì„ STT ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...</span>
            </div>
          )}

          {transcripts.length > 0 && (
            <div className="text-gray-800 leading-relaxed space-y-3">
              {timestampedSegments.length > 0 ? (
                // íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ìˆëŠ” ê²½ìš° - ì„¸ê·¸ë¨¼íŠ¸ë³„ í‘œì‹œ
                timestampedSegments.map((segment, index) => (
                  <div key={index} className="p-4 bg-gray-50 rounded-lg border border-gray-100">
                    <div className="text-xs text-gray-500 mb-2">
                      [{formatTime(segment.start)} - {formatTime(segment.end)}]
                    </div>
                    <div className="text-gray-800">
                      {segment.text || '(í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤)'}
                    </div>
                  </div>
                ))
              ) : (
                // íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ëŠ” ê²½ìš° - ì „ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ
                transcripts.map((transcript, index) => (
                  <div key={transcript.id} className="p-4 bg-gray-50 rounded-lg border border-gray-100">
                    <div className="text-xs text-gray-500 mb-2">
                      ë…¹ìŒ ì‹œê°„: {formatDuration(recordingDuration)} | 
                      ì²˜ë¦¬ ì™„ë£Œ: {new Date(transcript.processedAt).toLocaleTimeString('ko-KR')}
                    </div>
                    <div className={transcript.isError ? 'text-red-600 italic' : 'text-gray-800'}>
                      {transcript.text || '(í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤)'}
                    </div>
                  </div>
                ))
              )}
            </div>
          )}
        </div>
      </div>
    </div>
  );
};