/* eslint-env worker */
/* eslint-disable no-restricted-globals */
import { pipeline } from '@huggingface/transformers';
import { WorkerMessage, WorkerResponse } from '../types';

let transcriber: any = null;
let currentModel: string | null = null;
let lastLanguage: string | null = null;

self.addEventListener("message", async (event: MessageEvent<WorkerMessage>) => {
    const message = event.data;
    
    try {
        if (message.type === "load-model") {
            console.log("ğŸš€ Starting model loading:", message.model);
            currentModel = message.model || null;
            
            interface ModelCandidate {
                name: string;
                description: string;
                size: 'large' | 'turbo';
            }
            
            // ëª¨ë¸ í›„ë³´ ë¦¬ìŠ¤íŠ¸ (í° ëª¨ë¸ì—ì„œ ì‘ì€ ëª¨ë¸ë¡œ í´ë°±)
            const modelCandidates: ModelCandidate[] = [
                ...(currentModel ? [{ name: currentModel, description: 'ìš”ì²­ëœ ëª¨ë¸', size: 'large' as const }] : []),
                { name: 'onnx-community/whisper-large-v3-turbo', description: 'í° ëª¨ë¸', size: 'turbo' },
                { name: 'onnx-community/whisper-large-v3-turbo_timestamped', description: 'ê¸°ë³¸ ëª¨ë¸ ', size: 'turbo' }
            ];
            
            let modelLoaded = false;
            let lastError: Error | null = null;
            
            for (const model of modelCandidates) {
                if (modelLoaded) break;
                
                try {
                    console.log(`ğŸ”„ Attempting to load: ${model.description} (${model.name})`);
                    currentModel = model.name;
                    
                    const loadingMessage: WorkerResponse = {
                        type: 'loading',
                        status: 'downloading',
                        progress: 0,
                        message: `ì‹œë„ ì¤‘: ${model.description}`
                    };
                    self.postMessage(loadingMessage);
                    
                    // íƒ€ì„ì•„ì›ƒ ì„¤ì • (ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì¡°ì •)
                    const timeoutMs = model.size === 'large' ? 10 * 60 * 1000 : 5 * 60 * 1000; // ëŒ€í˜• ëª¨ë¸ 10ë¶„, ì†Œí˜• ëª¨ë¸ 5ë¶„
                    
                    const timeoutPromise = new Promise<never>((_, reject) => {
                        setTimeout(() => reject(new Error(`íƒ€ì„ì•„ì›ƒ: ${model.description} ë¡œë”©ì´ ${timeoutMs/60000}ë¶„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤`)), timeoutMs);
                    });
                    
                    const loadModelPromise = tryLoadModel(model);
                    
                    // íƒ€ì„ì•„ì›ƒê³¼ ì‹¤ì œ ë¡œë”© ë ˆì´ìŠ¤
                    const result = await Promise.race([loadModelPromise, timeoutPromise]);
                    
                    if (result && result.success && result.transcriber) {
                        console.log(`ğŸ‰ Successfully loaded ${model.description} using ${result.device}`);
                        transcriber = result.transcriber;
                        modelLoaded = true;
                        
                        // ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€ - ready ìƒíƒœë¡œ ë³€ê²½
                        const readyMessage: WorkerResponse = { 
                            type: 'loading',
                            status: 'ready',
                            progress: 100,
                            message: `${model.description} ë¡œë”© ì™„ë£Œ (${result.device})`
                        };
                        self.postMessage(readyMessage);
                        
                        break;
                    } else {
                        throw new Error(`ëª¨ë¸ ë¡œë”© ê²°ê³¼ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: ${JSON.stringify(result)}`);
                    }
                    
                } catch (modelError) {
                    const error = modelError instanceof Error ? modelError : new Error('ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜');
                    console.error(`âŒ Failed to load ${model.description}:`, error.message);
                    lastError = error;
                    
                    if (model === modelCandidates[modelCandidates.length - 1]) {
                        throw new Error(`ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: ${error.message}`);
                    } else {
                        console.log(`ğŸ”„ Trying next smaller model...`);
                        continue;
                    }
                }
            }
            
            if (!modelLoaded) {
                throw new Error(`ëª¨ë“  ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ${lastError?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
            }
            
        } else if (message.type === "transcribe") {
            // STT ìš”ì²­
            if (!transcriber) {
                console.error("âŒ Transcriber not available, current state:", {
                    transcriber,
                    currentModel
                });
                throw new Error("Transcriber not initialized. Please wait for model loading to complete.");
            }
            
            console.log("âœ… Transcriber is ready, processing audio...");
            
            const audioData = message.data?.audioData;
            const options = message.data?.options;
            
            if (!audioData) {
                throw new Error("Audio data not provided");
            }
            
            console.log("ğŸµ Starting transcription, audio length:", audioData.length);
            
            const transcribingMessage: WorkerResponse = {
                type: 'transcribing',
                message: 'STT ì²˜ë¦¬ ì¤‘...'
            };
            self.postMessage(transcribingMessage);
            
            const result = await transcribe({
                audio: audioData,
                model: currentModel || 'onnx-community/whisper-large-v3-turbo',
                subtask: options?.task || 'transcribe',
                language: options?.language,
                timestamp: options?.timestamp || Date.now(),
                options: {
                    return_timestamps: options?.return_timestamps || false
                }
            });
            
            if (result) {
                console.log("âœ… Transcription completed:", result.text);
                const resultMessage: WorkerResponse = {
                    type: "result",
                    text: result.text,
                    timestamp: result.timestamp
                };
                self.postMessage(resultMessage);
            }
        }
    } catch (error) {
        console.error("ğŸ’¥ Worker error:", error);
        // ë©”ì‹œì§€ì— í¬í•¨ëœ timestamp ë˜ëŠ” ì˜µì…˜ ë‚´ë¶€ timestampë¥¼ ì—ëŸ¬ì— í¬í•¨í•˜ì—¬ ìƒìœ„ íê°€ ë©ˆì¶”ì§€ ì•Šê²Œ í•¨
        const fallbackTimestamp = message?.data?.options?.timestamp;
        const errorMsg = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
        const errorMessage: WorkerResponse = {
            type: "error",
            message: errorMsg,
            timestamp: fallbackTimestamp
        };
        self.postMessage(errorMessage);
    }
});

interface ModelCandidate {
    name: string;
    description: string;
    size: 'large' | 'turbo';
}

interface LoadModelResult {
    success: boolean;
    transcriber: any;
    device: string;
}

async function tryLoadModel(model: ModelCandidate): Promise<LoadModelResult> {
    const startTime = Date.now();
    let progressCount = 0;
    let isCompleted = false;
    const maxCallbacks = 200; // ìµœëŒ€ ì½œë°± ìˆ˜ë¥¼ ëŒ€í­ ì¤„ì„
    
    // ê°•ì œ ì™„ë£Œ íƒ€ì´ë¨¸ (90ì´ˆ í›„ ê°•ì œ ì™„ë£Œ)
    const forceCompleteTimer = setTimeout(() => {
        if (!isCompleted) {
            console.log('â° 90ì´ˆ íƒ€ì„ì•„ì›ƒ - ê°•ì œ ì™„ë£Œ');
            isCompleted = true;
            const timeoutMessage: WorkerResponse = {
                type: 'loading',
                status: 'ready',
                progress: 100,
                message: `${model.description}: íƒ€ì„ì•„ì›ƒ ì™„ë£Œ`
            };
            self.postMessage(timeoutMessage);
        }
    }, 90 * 1000);
    
    const progress_callback = (data: any) => {
        // ì´ë¯¸ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ì™„ì „íˆ ë¬´ì‹œ
        if (isCompleted) {
            return;
        }
        
        progressCount++;
        const elapsed = Date.now() - startTime;
        
        // ì½œë°±ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ê°•ì œ ì™„ë£Œ
        if (progressCount >= maxCallbacks) {
            console.log(`ğŸ›‘ ì½œë°± ìˆ˜ ì´ˆê³¼ (${maxCallbacks}) - ê°•ì œ ì™„ë£Œ`);
            isCompleted = true;
            clearTimeout(forceCompleteTimer);
            const forceCompleteMessage: WorkerResponse = {
                type: 'loading',
                status: 'ready',
                progress: 100,
                message: `${model.description}: ê°•ì œ ì™„ë£Œ`
            };
            self.postMessage(forceCompleteMessage);
            return;
        }
        
        // ë¡œê·¸ëŠ” 10ë²ˆë§ˆë‹¤ë§Œ ì¶œë ¥
        if (progressCount % 10 === 0 || progressCount === 1) {
            console.log(`ğŸ“Š Progress #${progressCount}/${maxCallbacks} (${elapsed}ms): ${data.status} - ${Math.round((data.progress || 0) * 100)}%`);
        }
        
        // UI ì—…ë°ì´íŠ¸ëŠ” 20ë²ˆë§ˆë‹¤ë§Œ (ë¶€í•˜ ì¤„ì„)
        if (progressCount % 20 === 0 || progressCount === 1 || data.progress === 1.0) {
            let progress = Math.min(98, Math.round((data.progress || progressCount/maxCallbacks) * 100));
            
            const progressMessage: WorkerResponse = {
                type: 'loading',
                status: 'downloading',
                progress: progress,
                message: `${model.description}: ${progress}% (${Math.round(elapsed/1000)}ì´ˆ)`
            };
            self.postMessage(progressMessage);
        }
    };
    
    try {
        console.log("ğŸ”„ Trying WebGPU...");
        
        const transcriber = await pipeline("automatic-speech-recognition", model.name, {
            dtype: {
                encoder_model: "fp16",
                decoder_model_merged: "q4",
            },
            device: "webgpu",
            progress_callback
        });
        
        // ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
        isCompleted = true;
        clearTimeout(forceCompleteTimer);
        console.log(`âœ… WebGPU success in ${Date.now() - startTime}ms`);
        
        const webgpuCompleteMessage: WorkerResponse = {
            type: 'loading',
            status: 'ready',
            progress: 100,
            message: `${model.description}: WebGPU ì™„ë£Œ!`
        };
        self.postMessage(webgpuCompleteMessage);
        
        return { success: true, transcriber, device: 'WebGPU' };
        
    } catch (webgpuError) {
        const error = webgpuError instanceof Error ? webgpuError : new Error('ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜');
        console.warn("âŒ WebGPU failed:", error.message);
        
        try {
            console.log("ğŸ”„ Trying CPU fallback...");
            progressCount = 0; // ì§„í–‰ë¥  ë¦¬ì…‹
            
            const transcriber = await pipeline("automatic-speech-recognition", model.name, {
                dtype: {
                    encoder_model: "fp32",
                    decoder_model_merged: "fp32",
                },
                device: "cpu",
                progress_callback
            });
            
            // ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
            isCompleted = true;
            clearTimeout(forceCompleteTimer);
            console.log(`âœ… CPU success in ${Date.now() - startTime}ms`);
            
            const cpuCompleteMessage: WorkerResponse = {
                type: 'loading',
                status: 'ready',
                progress: 100,
                message: `${model.description}: CPU ì™„ë£Œ!`
            };
            self.postMessage(cpuCompleteMessage);
            
            return { success: true, transcriber, device: 'CPU' };
            
        } catch (cpuError) {
            isCompleted = true;
            clearTimeout(forceCompleteTimer);
            console.error("âŒ Both WebGPU and CPU failed");
            const error = cpuError instanceof Error ? cpuError : new Error('ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜');
            throw error;
        }
    }
}

interface TranscribeOptions {
    audio: Float32Array;
    model: string;
    subtask?: string;
    language?: string | null;
    timestamp: number;
    options?: {
        return_timestamps?: boolean;
    };
}

interface TranscribeResult {
    text: string;
    timestamp: number;
    chunks?: Array<{
        text: string;
        timestamp: [number, number];
    }> | null;
}

const transcribe = async ({ audio, model, subtask = "transcribe", language = null, timestamp, options }: TranscribeOptions): Promise<TranscribeResult> => {
    try {
        // audioê°€ Float32Arrayì¸ì§€ í™•ì¸
        if (!(audio instanceof Float32Array)) {
            console.log("ğŸ”„ Converting audio to Float32Array");
            audio = new Float32Array(audio);
        }

        // ì˜¤ë””ì˜¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if (audio.length === 0) {
            throw new Error("Audio data is empty");
        }

        console.log("ğŸµ Processing audio data, length:", audio.length, "language:", language);

        // ì§€ì •ëœ ì–¸ì–´ë¡œ ì²˜ë¦¬
        const lang = language === 'korean' ? 'ko' : language === 'english' ? 'en' : language;
        console.log("ğŸ¯ ì§€ì • ì–¸ì–´ë¡œ ì²˜ë¦¬:", lang);
        
        const result = await transcriber(audio, {
            task: subtask,
            language: lang,
            return_timestamps: options?.return_timestamps || false,
        });
        
        return {
            text: result.text?.trim() || '',
            timestamp: timestamp,
            chunks: result.chunks || null
        };
    } catch (error) {
        console.error("âŒ Transcription error:", error);
        throw error;
    }
};