/* eslint-env worker */
/* eslint-disable no-restricted-globals */
import { pipeline } from '@huggingface/transformers';

let transcriber = null;
let currentModel = null;

self.addEventListener("message", async (event) => {
    const message = event.data;
    
    try {
        if (message.type === "load-model") {
            console.log("ğŸš€ Starting model loading:", message.model);
            currentModel = message.model;
            
            // ëª¨ë¸ í›„ë³´ ë¦¬ìŠ¤íŠ¸ (í° ëª¨ë¸ì—ì„œ ì‘ì€ ëª¨ë¸ë¡œ í´ë°±)
            const modelCandidates = [
                { name: currentModel, description: 'ìš”ì²­ëœ ëª¨ë¸', size: 'large' },
                { name: 'onnx-community/whisper-large-v3-turbo', description: 'í° ëª¨ë¸', size: 'turbo' },
                { name: 'onnx-community/whisper-large-v3-turbo_timestamped', description: 'ê¸°ë³¸ ëª¨ë¸ ', size: 'turbo' }
            ];
            
            let modelLoaded = false;
            let lastError = null;
            
            for (const model of modelCandidates) {
                if (modelLoaded) break;
                
                try {
                    console.log(`ğŸ”„ Attempting to load: ${model.description} (${model.name})`);
                    currentModel = model.name;
                    
                    self.postMessage({
                        type: 'loading',
                        status: 'downloading',
                        progress: 0,
                        message: `ì‹œë„ ì¤‘: ${model.description}`
                    });
                    
                    // íƒ€ì„ì•„ì›ƒ ì„¤ì • (ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì¡°ì •)
                    const timeoutMs = model.size === 'large' ? 10 * 60 * 1000 : 5 * 60 * 1000; // ëŒ€í˜• ëª¨ë¸ 10ë¶„, ì†Œí˜• ëª¨ë¸ 5ë¶„
                    
                    const timeoutPromise = new Promise((_, reject) => {
                        setTimeout(() => reject(new Error(`íƒ€ì„ì•„ì›ƒ: ${model.description} ë¡œë”©ì´ ${timeoutMs/60000}ë¶„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤`)), timeoutMs);
                    });
                    
                    const loadModelPromise = tryLoadModel(model);
                    
                    // íƒ€ì„ì•„ì›ƒê³¼ ì‹¤ì œ ë¡œë”© ë ˆì´ìŠ¤
                    const result = await Promise.race([loadModelPromise, timeoutPromise]);
                    
                    if (result && result.success && result.transcriber) {
                        console.log(`ğŸ‰ Successfully loaded ${model.description} using ${result.device}`);
                        transcriber = result.transcriber;
                        modelLoaded = true;
                        
                        // ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€ - ready ìƒíƒœë¡œ ë³€ê²½
                        self.postMessage({ 
                            type: 'loading',
                            status: 'ready',
                            progress: 100,
                            message: `${model.description} ë¡œë”© ì™„ë£Œ (${result.device})`
                        });
                        
                        break;
                    } else {
                        throw new Error(`ëª¨ë¸ ë¡œë”© ê²°ê³¼ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: ${JSON.stringify(result)}`);
                    }
                    
                } catch (modelError) {
                    console.error(`âŒ Failed to load ${model.description}:`, modelError.message);
                    lastError = modelError;
                    
                    if (model === modelCandidates[modelCandidates.length - 1]) {
                        throw new Error(`ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: ${modelError.message}`);
                    } else {
                        console.log(`ğŸ”„ Trying next smaller model...`);
                        continue;
                    }
                }
            }
            
            if (!modelLoaded) {
                throw new Error(`ëª¨ë“  ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ${lastError?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
            }
            
        } else if (message.type === "transcribe") {
            // STT ìš”ì²­
            if (!transcriber) {
                throw new Error("Transcriber not initialized");
            }
            
            const audioData = message.data?.audioData;
            const options = message.data?.options || {};
            
            if (!audioData) {
                throw new Error("Audio data not provided");
            }
            
            console.log("ğŸµ Starting transcription, audio length:", audioData.length);
            
            self.postMessage({
                type: 'transcribing',
                message: 'STT ì²˜ë¦¬ ì¤‘...'
            });
            
            const result = await transcribe({
                audio: audioData,
                model: currentModel,
                subtask: options.task || 'transcribe',
                language: options.language || 'ko',
                timestamp: options.timestamp
            });
            
            if (result) {
                console.log("âœ… Transcription completed:", result.text);
                self.postMessage({
                    type: "result",
                    text: result.text,
                    timestamp: result.timestamp
                });
            }
        }
    } catch (error) {
        console.error("ğŸ’¥ Worker error:", error);
        // ë©”ì‹œì§€ì— í¬í•¨ëœ timestamp ë˜ëŠ” ì˜µì…˜ ë‚´ë¶€ timestampë¥¼ ì—ëŸ¬ì— í¬í•¨í•˜ì—¬ ìƒìœ„ íê°€ ë©ˆì¶”ì§€ ì•Šê²Œ í•¨
        const fallbackTimestamp = message?.data?.options?.timestamp || message?.timestamp;
        self.postMessage({
            type: "error",
            message: error.message,
            timestamp: fallbackTimestamp
        });
    }
});

async function tryLoadModel(model) {
    const startTime = Date.now();
    let progressCount = 0;
    let isCompleted = false;
    const maxCallbacks = 200; // ìµœëŒ€ ì½œë°± ìˆ˜ë¥¼ ëŒ€í­ ì¤„ì„
    
    // ê°•ì œ ì™„ë£Œ íƒ€ì´ë¨¸ (90ì´ˆ í›„ ê°•ì œ ì™„ë£Œ)
    const forceCompleteTimer = setTimeout(() => {
        if (!isCompleted) {
            console.log('â° 90ì´ˆ íƒ€ì„ì•„ì›ƒ - ê°•ì œ ì™„ë£Œ');
            isCompleted = true;
            self.postMessage({
                type: 'loading',
                status: 'ready',
                progress: 100,
                message: `${model.description}: íƒ€ì„ì•„ì›ƒ ì™„ë£Œ`
            });
        }
    }, 90 * 1000);
    
    const progress_callback = (data) => {
        // ì´ë¯¸ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ì™„ì „íˆ ë¬´ì‹œ
        if (isCompleted) {
            return;
        }
        
        progressCount++;
        const elapsed = Date.now() - startTime;
        
        // ì½œë°±ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ê°•ì œ ì™„ë£Œ
        if (progressCount >= maxCallbacks) {
            console.log(`ğŸ›‘ ì½œë°± ìˆ˜ ì´ˆê³¼ (${maxCallbacks}) - ê°•ì œ ì™„ë£Œ`);
            isCompleted = true;
            clearTimeout(forceCompleteTimer);
            self.postMessage({
                type: 'loading',
                status: 'ready',
                progress: 100,
                message: `${model.description}: ê°•ì œ ì™„ë£Œ`
            });
            return;
        }
        
        // ë¡œê·¸ëŠ” 10ë²ˆë§ˆë‹¤ë§Œ ì¶œë ¥
        if (progressCount % 10 === 0 || progressCount === 1) {
            console.log(`ğŸ“Š Progress #${progressCount}/${maxCallbacks} (${elapsed}ms): ${data.status} - ${Math.round((data.progress || 0) * 100)}%`);
        }
        
        // UI ì—…ë°ì´íŠ¸ëŠ” 20ë²ˆë§ˆë‹¤ë§Œ (ë¶€í•˜ ì¤„ì„)
        if (progressCount % 20 === 0 || progressCount === 1 || data.progress === 1.0) {
            let progress = Math.min(98, Math.round((data.progress || progressCount/maxCallbacks) * 100));
            
            self.postMessage({
                type: 'loading',
                status: 'downloading',
                progress: progress,
                message: `${model.description}: ${progress}% (${Math.round(elapsed/1000)}ì´ˆ)`
            });
        }
    };
    
    try {
        console.log("ğŸ”„ Trying WebGPU...");
        
        const transcriber = await pipeline("automatic-speech-recognition", model.name, {
            dtype: {
                encoder_model: "fp16",
                decoder_model_merged: "q4",
            },
            device: "webgpu",
            progress_callback
        });
        
        // ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
        isCompleted = true;
        clearTimeout(forceCompleteTimer);
        console.log(`âœ… WebGPU success in ${Date.now() - startTime}ms`);
        
        self.postMessage({
            type: 'loading',
            status: 'ready',
            progress: 100,
            message: `${model.description}: WebGPU ì™„ë£Œ!`
        });
        
        return { success: true, transcriber, device: 'WebGPU' };
        
    } catch (webgpuError) {
        console.warn("âŒ WebGPU failed:", webgpuError.message);
        
        try {
            console.log("ğŸ”„ Trying CPU fallback...");
            progressCount = 0; // ì§„í–‰ë¥  ë¦¬ì…‹
            
            const transcriber = await pipeline("automatic-speech-recognition", model.name, {
                dtype: {
                    encoder_model: "fp32",
                    decoder_model_merged: "fp32",
                },
                device: "cpu",
                progress_callback
            });
            
            // ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
            isCompleted = true;
            clearTimeout(forceCompleteTimer);
            console.log(`âœ… CPU success in ${Date.now() - startTime}ms`);
            
            self.postMessage({
                type: 'loading',
                status: 'ready',
                progress: 100,
                message: `${model.description}: CPU ì™„ë£Œ!`
            });
            
            return { success: true, transcriber, device: 'CPU' };
            
        } catch (cpuError) {
            isCompleted = true;
            clearTimeout(forceCompleteTimer);
            console.error("âŒ Both WebGPU and CPU failed");
            throw cpuError;
        }
    }
}

const transcribe = async ({ audio, model, subtask = "transcribe", language = "ko", timestamp }) => {
    try {
        // audioê°€ Float32Arrayì¸ì§€ í™•ì¸
        if (!(audio instanceof Float32Array)) {
            console.log("ğŸ”„ Converting audio to Float32Array");
            audio = new Float32Array(audio);
        }

        // ì˜¤ë””ì˜¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if (audio.length === 0) {
            throw new Error("Audio data is empty");
        }

        console.log("ğŸµ Processing audio data, length:", audio.length, "language:", language);

        // STT ì‹¤í–‰
        const result = await transcriber(audio, {
            task: subtask,
            language: language,
            return_timestamps: false,
        });
        
        return {
            text: result.text?.trim() || '',
            timestamp: timestamp
        };
    } catch (error) {
        console.error("âŒ Transcription error:", error);
        throw error;
    }
};